{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNIVERSIDADE ESTADUAL DO CEARÁ \\\n",
    "MESTRADO ACADÊMICO EM CIÊNCIA DA COMPUTAÇÃO \\\n",
    "MINERAÇÃO MASSIVA DE DADOS\n",
    "\n",
    "Daniel Gleison Moreira Lira \\\n",
    "daniel.gleison@aluno.uece.br\n",
    "\n",
    "Atualizado em 23/10/2020\n",
    "\n",
    "\n",
    "\n",
    "# Mecanismo de predição de fraudes financeiras utilizando aprendizado de máquina e computação distribuída\n",
    "---\n",
    "\n",
    "\n",
    "## Database\n",
    "\n",
    "https://www.kaggle.com/ntnu-testimon/paysim1\n",
    "\n",
    "PS_20174392719_1491204439457_log.csv\\\n",
    "Date created: 2017-03-31\n",
    "\n",
    "### Predicted attribute:\n",
    "Class of fraud detection\n",
    "\n",
    "### Number of Instances:\n",
    "6.353.307\n",
    "\n",
    "### Number of Attributes:\n",
    "11 attributes (5 Decimal, 3 Integer, 3 String) and the class\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "This is a sample of 1 row with headers explanation:\n",
    "\n",
    "1,PAYMENT,1060.31,C429214117,1089.0,28.69,M1591654462,0.0,0.0,0,0\n",
    "\n",
    "step - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).\n",
    "\n",
    "type - CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.\n",
    "\n",
    "amount - amount of the transaction in local currency.\n",
    "\n",
    "nameOrig - customer who started the transaction\n",
    "\n",
    "oldbalanceOrg - initial balance before the transaction\n",
    "\n",
    "newbalanceOrig - new balance after the transaction\n",
    "\n",
    "nameDest - customer who is the recipient of the transaction\n",
    "\n",
    "oldbalanceDest - initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants).\n",
    "\n",
    "newbalanceDest - new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants).\n",
    "\n",
    "isFraud - This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.\n",
    "\n",
    "isFlaggedFraud - The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction.\n",
    "\n",
    "### Missing Attribute Values: \n",
    "None\n",
    "\n",
    "### Class Distribution: \n",
    "2 Classes \\\n",
    "6.354.407 without fraud and 8.213 with fraud\n",
    "\n",
    "## References:\n",
    "\n",
    "1. E. A. Lopez-Rojas , A. Elmir, and S. Axelsson. \"PaySim: A financial mobile money simulator for fraud detection\". In: The 28th European Modeling and Simulation Symposium-EMSS, Larnaca, Cyprus. 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Lib\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "## SKLearn Lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from joblib import dump, load\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do ambiente Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.129.64.20:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MachineLearningFraud</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2ccffaa978>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"MachineLearningFraud\") \\\n",
    "        .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação e compreensão dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|step|    type|   amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|   1| PAYMENT|  9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER|    181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|      1|             0|\n",
      "|   1|CASH_OUT|    181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|      1|             0|\n",
      "|   1| PAYMENT| 11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  7817.71|  C90045638|      53860.0|      46042.29| M573487274|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  7107.77| C154988899|     183195.0|     176087.23| M408069119|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  7861.64|C1912850431|    176087.23|     168225.59| M633326333|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  4024.36|C1265012928|       2671.0|           0.0|M1176932104|           0.0|           0.0|      0|             0|\n",
      "|   1|   DEBIT|  5337.77| C712410124|      41720.0|      36382.23| C195600860|       41898.0|      40348.79|      0|             0|\n",
      "|   1|   DEBIT|  9644.94|C1900366749|       4465.0|           0.0| C997608398|       10845.0|     157982.12|      0|             0|\n",
      "|   1| PAYMENT|  3099.97| C249177573|      20771.0|      17671.03|M2096539129|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  2560.74|C1648232591|       5070.0|       2509.26| M972865270|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT| 11633.76|C1716932897|      10127.0|           0.0| M801569151|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  4098.78|C1026483832|     503264.0|     499165.22|M1635378213|           0.0|           0.0|      0|             0|\n",
      "|   1|CASH_OUT|229133.94| C905080434|      15325.0|           0.0| C476402209|        5083.0|      51513.44|      0|             0|\n",
      "|   1| PAYMENT|  1563.82| C761750706|        450.0|           0.0|M1731217984|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|  1157.86|C1237762639|      21156.0|      19998.14|M1877062907|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT|   671.64|C2033524545|      15123.0|      14451.36| M473053293|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER| 215310.3|C1670993182|        705.0|           0.0|C1100439041|       22425.0|           0.0|      0|             0|\n",
      "+----+--------+---------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path='./data/'\n",
    "df_original = spark.read.format('csv')\\\n",
    "                   .options(sep=',',header='true',inferschema='true').\\\n",
    "                   load(data_path+'PS_20174392719_1491204439457_log.csv')\n",
    "df_original.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|isFraud|  count|\n",
      "+-------+-------+\n",
      "|      0|6354407|\n",
      "+-------+-------+\n",
      "\n",
      "+-------+-----+\n",
      "|isFraud|count|\n",
      "+-------+-----+\n",
      "|      1| 8213|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df0 = df_original[df_original.isFraud==0]\n",
    "df1 = df_original[df_original.isFraud==1]\n",
    "df0.groupby('isFraud').count().show()\n",
    "df1.groupby('isFraud').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|isFraud|count|\n",
      "+-------+-----+\n",
      "|      0| 8213|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guessedFraction = 1.0\n",
    "noOfSamples = df1.count()\n",
    "df0 = df0.sample(True, guessedFraction).limit(noOfSamples)\n",
    "df0.groupby('isFraud').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16426"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanceado = df0.union(df1)\n",
    "df_balanceado.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise exploratória dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df_balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- nameOrig: string (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- nameDest: string (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- isFraud: integer (nullable = true)\n",
      " |-- isFlaggedFraud: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_original.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16426"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|IsFraud|count|\n",
      "+-------+-----+\n",
      "|      1| 8213|\n",
      "|      0| 8213|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_original.groupBy('IsFraud').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|isFlaggedFraud|count|\n",
      "+--------------+-----+\n",
      "|             1|   16|\n",
      "|             0|16410|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_original.groupBy('isFlaggedFraud').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estatística descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <td>16426</td>\n",
       "      <td>185.98344088639962</td>\n",
       "      <td>238.10960108876253</td>\n",
       "      <td>1</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>16426</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>TRANSFER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <td>16426</td>\n",
       "      <td>782382.2715463294</td>\n",
       "      <td>1839555.886107465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0E7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nameOrig</th>\n",
       "      <td>16426</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>C1000036340</td>\n",
       "      <td>C999864329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <td>16426</td>\n",
       "      <td>1290386.3020224043</td>\n",
       "      <td>2968752.08120663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.958504037E7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <td>16426</td>\n",
       "      <td>574737.2564872755</td>\n",
       "      <td>2140685.0270821685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.958504037E7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nameDest</th>\n",
       "      <td>16426</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>C1000039615</td>\n",
       "      <td>M999221400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <td>16426</td>\n",
       "      <td>744096.2936320467</td>\n",
       "      <td>3034475.953579213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3623051682E8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newbalanceDest</th>\n",
       "      <td>16426</td>\n",
       "      <td>1190471.7977517343</td>\n",
       "      <td>3504874.881273131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3672649466E8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFraud</th>\n",
       "      <td>16426</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5000152204684895</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <td>16426</td>\n",
       "      <td>9.740655059052721E-4</td>\n",
       "      <td>0.031195768116294764</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                     1                     2  \\\n",
       "summary         count                  mean                stddev   \n",
       "step            16426    185.98344088639962    238.10960108876253   \n",
       "type            16426                  None                  None   \n",
       "amount          16426     782382.2715463294     1839555.886107465   \n",
       "nameOrig        16426                  None                  None   \n",
       "oldbalanceOrg   16426    1290386.3020224043      2968752.08120663   \n",
       "newbalanceOrig  16426     574737.2564872755    2140685.0270821685   \n",
       "nameDest        16426                  None                  None   \n",
       "oldbalanceDest  16426     744096.2936320467     3034475.953579213   \n",
       "newbalanceDest  16426    1190471.7977517343     3504874.881273131   \n",
       "isFraud         16426                   0.5    0.5000152204684895   \n",
       "isFlaggedFraud  16426  9.740655059052721E-4  0.031195768116294764   \n",
       "\n",
       "                          3               4  \n",
       "summary                 min             max  \n",
       "step                      1             743  \n",
       "type                CASH_IN        TRANSFER  \n",
       "amount                  0.0           1.0E7  \n",
       "nameOrig        C1000036340      C999864329  \n",
       "oldbalanceOrg           0.0   5.958504037E7  \n",
       "newbalanceOrig          0.0   4.958504037E7  \n",
       "nameDest        C1000039615      M999221400  \n",
       "oldbalanceDest          0.0  2.3623051682E8  \n",
       "newbalanceDest          0.0  2.3672649466E8  \n",
       "isFraud                   0               1  \n",
       "isFlaggedFraud            0               1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação de valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "|step|type|amount|nameOrig|oldbalanceOrg|newbalanceOrig|nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "|   0|   0|     0|       0|            0|             0|       0|             0|             0|      0|             0|\n",
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, count, col\n",
    "df_original.select([count(when(isnull(c), c)).alias(c) for c in df_original.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix de correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.314259</td>\n",
       "      <td>0.127043</td>\n",
       "      <td>-0.112525</td>\n",
       "      <td>-0.040873</td>\n",
       "      <td>0.033887</td>\n",
       "      <td>0.766185</td>\n",
       "      <td>0.046107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <td>0.314259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.720727</td>\n",
       "      <td>0.144021</td>\n",
       "      <td>-0.006876</td>\n",
       "      <td>0.252523</td>\n",
       "      <td>0.372702</td>\n",
       "      <td>0.069244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <td>0.127043</td>\n",
       "      <td>0.720727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784409</td>\n",
       "      <td>0.067099</td>\n",
       "      <td>0.201479</td>\n",
       "      <td>0.121025</td>\n",
       "      <td>0.068658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <td>-0.112525</td>\n",
       "      <td>0.144021</td>\n",
       "      <td>0.784409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125671</td>\n",
       "      <td>0.086783</td>\n",
       "      <td>-0.178614</td>\n",
       "      <td>0.105656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <td>-0.040873</td>\n",
       "      <td>-0.006876</td>\n",
       "      <td>0.067099</td>\n",
       "      <td>0.125671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899212</td>\n",
       "      <td>-0.065861</td>\n",
       "      <td>-0.007657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newbalanceDest</th>\n",
       "      <td>0.033887</td>\n",
       "      <td>0.252523</td>\n",
       "      <td>0.201479</td>\n",
       "      <td>0.086783</td>\n",
       "      <td>0.899212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025461</td>\n",
       "      <td>-0.010606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFraud</th>\n",
       "      <td>0.766185</td>\n",
       "      <td>0.372702</td>\n",
       "      <td>0.121025</td>\n",
       "      <td>-0.178614</td>\n",
       "      <td>-0.065861</td>\n",
       "      <td>0.025461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <td>0.046107</td>\n",
       "      <td>0.069244</td>\n",
       "      <td>0.068658</td>\n",
       "      <td>0.105656</td>\n",
       "      <td>-0.007657</td>\n",
       "      <td>-0.010606</td>\n",
       "      <td>0.031225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    step    amount  oldbalanceOrg  newbalanceOrig  \\\n",
       "step            1.000000  0.314259       0.127043       -0.112525   \n",
       "amount          0.314259  1.000000       0.720727        0.144021   \n",
       "oldbalanceOrg   0.127043  0.720727       1.000000        0.784409   \n",
       "newbalanceOrig -0.112525  0.144021       0.784409        1.000000   \n",
       "oldbalanceDest -0.040873 -0.006876       0.067099        0.125671   \n",
       "newbalanceDest  0.033887  0.252523       0.201479        0.086783   \n",
       "isFraud         0.766185  0.372702       0.121025       -0.178614   \n",
       "isFlaggedFraud  0.046107  0.069244       0.068658        0.105656   \n",
       "\n",
       "                oldbalanceDest  newbalanceDest   isFraud  isFlaggedFraud  \n",
       "step                 -0.040873        0.033887  0.766185        0.046107  \n",
       "amount               -0.006876        0.252523  0.372702        0.069244  \n",
       "oldbalanceOrg         0.067099        0.201479  0.121025        0.068658  \n",
       "newbalanceOrig        0.125671        0.086783 -0.178614        0.105656  \n",
       "oldbalanceDest        1.000000        0.899212 -0.065861       -0.007657  \n",
       "newbalanceDest        0.899212        1.000000  0.025461       -0.010606  \n",
       "isFraud              -0.065861        0.025461  1.000000        0.031225  \n",
       "isFlaggedFraud       -0.007657       -0.010606  0.031225        1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.toPandas().corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexação dos atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+---------+-----+\n",
      "|step|   type| amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|indexType|label|\n",
      "+----+-------+-------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+---------+-----+\n",
      "|   1|PAYMENT|9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|      0|             0|      2.0|  0.0|\n",
      "|   1|PAYMENT|7861.64|C1912850431|    176087.23|     168225.59| M633326333|           0.0|           0.0|      0|             0|      2.0|  0.0|\n",
      "|   1|PAYMENT|4024.36|C1265012928|       2671.0|           0.0|M1176932104|           0.0|           0.0|      0|             0|      2.0|  0.0|\n",
      "|   1|  DEBIT|5337.77| C712410124|      41720.0|      36382.23| C195600860|       41898.0|      40348.79|      0|             0|      4.0|  0.0|\n",
      "|   1|  DEBIT|5337.77| C712410124|      41720.0|      36382.23| C195600860|       41898.0|      40348.79|      0|             0|      4.0|  0.0|\n",
      "+----+-------+-------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol='type', outputCol='indexType').fit(df_original)\n",
    "df_indexado = indexer.transform(df_original)\n",
    "\n",
    "indexer = StringIndexer(inputCol='isFraud', outputCol='label').fit(df_original)\n",
    "df_indexado = indexer.transform(df_indexado)\n",
    "\n",
    "labelReverse = IndexToString().setInputCol('label')\n",
    "indexTypeReverse = IndexToString().setInputCol('indexType')\n",
    "\n",
    "df_indexado.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclusão de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------------+--------------+--------------+--------------+---------+-----+\n",
      "|step| amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|indexType|label|\n",
      "+----+-------+-------------+--------------+--------------+--------------+---------+-----+\n",
      "|   1|9839.64|     170136.0|     160296.36|           0.0|           0.0|      2.0|  0.0|\n",
      "|   1|7861.64|    176087.23|     168225.59|           0.0|           0.0|      2.0|  0.0|\n",
      "|   1|4024.36|       2671.0|           0.0|           0.0|           0.0|      2.0|  0.0|\n",
      "|   1|5337.77|      41720.0|      36382.23|       41898.0|      40348.79|      4.0|  0.0|\n",
      "|   1|5337.77|      41720.0|      36382.23|       41898.0|      40348.79|      4.0|  0.0|\n",
      "+----+-------+-------------+--------------+--------------+--------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_selecionado = df_indexado.drop('type','nameOrig','nameDest','isFraud','isFlaggedFraud')\n",
    "df_selecionado.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção dos atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------------+--------------+--------------+--------------+---------+-----+\n",
      "|step| amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|indexType|label|\n",
      "+----+-------+-------------+--------------+--------------+--------------+---------+-----+\n",
      "|   1|9839.64|     170136.0|     160296.36|           0.0|           0.0|      2.0|  0.0|\n",
      "|   1|7861.64|    176087.23|     168225.59|           0.0|           0.0|      2.0|  0.0|\n",
      "|   1|4024.36|       2671.0|           0.0|           0.0|           0.0|      2.0|  0.0|\n",
      "|   1|5337.77|      41720.0|      36382.23|       41898.0|      40348.79|      4.0|  0.0|\n",
      "|   1|5337.77|      41720.0|      36382.23|       41898.0|      40348.79|      4.0|  0.0|\n",
      "+----+-------+-------------+--------------+--------------+--------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_selecionado.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação da matrix de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------+\n",
      "|label|features                                           |\n",
      "+-----+---------------------------------------------------+\n",
      "|0.0  |[1.0,9839.64,170136.0,160296.36,0.0,0.0,2.0]       |\n",
      "|0.0  |[1.0,7861.64,176087.23,168225.59,0.0,0.0,2.0]      |\n",
      "|0.0  |[1.0,4024.36,2671.0,0.0,0.0,0.0,2.0]               |\n",
      "|0.0  |[1.0,5337.77,41720.0,36382.23,41898.0,40348.79,4.0]|\n",
      "|0.0  |[1.0,5337.77,41720.0,36382.23,41898.0,40348.79,4.0]|\n",
      "+-----+---------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16426"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore = ['label']\n",
    "list = [x for x in df_selecionado.columns if x not in ignore]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "            inputCols= list,\n",
    "            outputCol='features')\n",
    "\n",
    "df_transformado = (assembler.transform(df_selecionado).select('label','features'))\n",
    "df_transformado.show(truncate = False, n = 5)\n",
    "df_transformado.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão do dataset para treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentual da base de treinamento 70.0 %\n",
      "Percentual da base de teste 30.0 %\n",
      "Quantidade de registros da base de treinamento: 11559\n",
      "Quantidade de registros da base de treinamento: 4867\n"
     ]
    }
   ],
   "source": [
    "train_sample = 0.7\n",
    "test_sample = 0.3\n",
    "seed = 1234\n",
    "\n",
    "(train, test) = df_transformado.randomSplit([train_sample, test_sample],seed)\n",
    "\n",
    "num_train = df_transformado.count() * train_sample\n",
    "num_test = df_transformado.count() * test_sample\n",
    "\n",
    "print('Percentual da base de treinamento', train_sample*100, '%')\n",
    "print('Percentual da base de teste', test_sample*100, '%')\n",
    "print('Quantidade de registros da base de treinamento:', train.count())\n",
    "print('Quantidade de registros da base de treinamento:', test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 5773|\n",
      "|  1.0| 5786|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 2440|\n",
      "|  1.0| 2427|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento, execução e avaliação dos modelos de predição"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo de predição\n",
    "start_time = time.time()\n",
    "trainer = DecisionTreeClassifier(featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability',\\\n",
    "                                 rawPredictionCol='rawPrediction', maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0,\\\n",
    "                                 maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity='gini', seed=None)\n",
    "model_dt = trainer.fit(train)\n",
    "time_dt_train = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução do modelo de predição na base de teste\n",
    "start_time = time.time()\n",
    "result_dt = model_dt.transform(test)\n",
    "time_dt_pred = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da acurácia do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='accuracy')\n",
    "accuracy_dt = evaluator.evaluate(result_dt) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo do recall do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedRecall')\n",
    "recall_dt = evaluator.evaluate(result_dt) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da precisão do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedPrecision')\n",
    "precision_dt = evaluator.evaluate(result_dt) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da F1 score do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='f1')\n",
    "f1_dt = evaluator.evaluate(result_dt) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2440    0]\n",
      " [  15 2412]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusão\n",
    "y_true = result_dt.select(\"label\").toPandas()\n",
    "y_pred = result_dt.select(\"prediction\").toPandas()\n",
    "mc_dt = confusion_matrix(y_true, y_pred)\n",
    "tn_dt, fp_dt, fn_dt, tp_dt = confusion_matrix(y_true, y_pred).ravel()\n",
    "print(mc_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados do modelo Decision Tree:\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|acurácia|recall|precisão|f1 score|falso positivo|falso negativo|tempo treinamento|tempo predição|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|   99.69| 99.69|   99.69|   99.69|             0|            15|             9.18|          0.09|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibição dos resultados\n",
    "evaluator_dt = spark.createDataFrame(\n",
    "    [(round(accuracy_dt,2), round(recall_dt,2), round(precision_dt,2), round(f1_dt,2),\\\n",
    "      int(fp_dt), int(fn_dt),\\\n",
    "      round(time_dt_train,2), round(time_dt_pred,2))],\\\n",
    "    ['acurácia','recall','precisão','f1 score',\\\n",
    "     'falso positivo', 'falso negativo',\\\n",
    "     'tempo treinamento','tempo predição'])\n",
    "print(\"Resultados do modelo Decision Tree:\")\n",
    "evaluator_dt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------+-------------+-----------------------------------------+----------+\n",
      "|label|features                             |rawPrediction|probability                              |prediction|\n",
      "+-----+-------------------------------------+-------------+-----------------------------------------+----------+\n",
      "|0.0  |(7,[0,1,4],[1.0,10782.94,100585.0])  |[1087.0,15.0]|[0.9863883847549909,0.013611615245009074]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[1087.0,15.0]|[0.9863883847549909,0.013611615245009074]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[1087.0,15.0]|[0.9863883847549909,0.013611615245009074]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,34629.16,38735.74])  |[1087.0,15.0]|[0.9863883847549909,0.013611615245009074]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,193605.38,249452.05])|[1087.0,15.0]|[0.9863883847549909,0.013611615245009074]|0.0       |\n",
      "+-----+-------------------------------------+-------------+-----------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_dt.show(truncate = False, n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo de predição\n",
    "start_time = time.time()\n",
    "trainer = RandomForestClassifier(featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability',\\\n",
    "                                 rawPredictionCol='rawPrediction', maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0,\\\n",
    "                                 numTrees=50, featureSubsetStrategy='auto', seed=None, subsamplingRate=1.0,\\\n",
    "                                 maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity='gini')\n",
    "model_rf = trainer.fit(train)\n",
    "time_rf_train = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução do modelo de predição na base de teste\n",
    "start_time = time.time()\n",
    "result_rf = model_rf.transform(test)\n",
    "time_rf_pred = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da acurácia do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='accuracy')\n",
    "accuracy_rf = evaluator.evaluate(result_rf) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo do recall do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedRecall')\n",
    "recall_rf = evaluator.evaluate(result_rf) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da precisão do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedPrecision')\n",
    "precision_rf = evaluator.evaluate(result_rf) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da F1 score do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='f1')\n",
    "f1_rf = evaluator.evaluate(result_rf) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2440    0]\n",
      " [  14 2413]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusão\n",
    "y_true = result_rf.select(\"label\").toPandas()\n",
    "y_pred = result_rf.select(\"prediction\").toPandas()\n",
    "mc_rf = confusion_matrix(y_true, y_pred)\n",
    "tn_rf, fp_rf, fn_rf, tp_rf = confusion_matrix(y_true, y_pred).ravel()\n",
    "print(mc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados do modelo Random Forest:\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|acurácia|recall|precisão|f1 score|falso positivo|falso negativo|tempo treinamento|tempo predição|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|   99.71| 99.71|   99.71|   99.71|             0|            14|             9.96|          0.09|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibição dos resultados\n",
    "evaluator_rf = spark.createDataFrame(\n",
    "    [(round(accuracy_rf,2), round(recall_rf,2), round(precision_rf,2), round(f1_rf,2),\\\n",
    "      int(fp_rf), int(fn_rf),\\\n",
    "      round(time_rf_train,2), round(time_rf_pred,2))],\\\n",
    "    ['acurácia','recall','precisão','f1 score',\\\n",
    "     'falso positivo', 'falso negativo',\\\n",
    "     'tempo treinamento','tempo predição'])\n",
    "print(\"Resultados do modelo Random Forest:\")\n",
    "evaluator_rf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------+---------------------------------------+-----------------------------------------+----------+\n",
      "|label|features                             |rawPrediction                          |probability                              |prediction|\n",
      "+-----+-------------------------------------+---------------------------------------+-----------------------------------------+----------+\n",
      "|0.0  |(7,[0,1,4],[1.0,10782.94,100585.0])  |[48.93452715114445,1.0654728488555614] |[0.9786905430228887,0.021309456977111223]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[48.93452715114445,1.0654728488555614] |[0.9786905430228887,0.021309456977111223]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[48.93452715114445,1.0654728488555614] |[0.9786905430228887,0.021309456977111223]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,34629.16,38735.74])  |[49.1429428335959,0.8570571664041015]  |[0.982858856671918,0.017141143328082028] |0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,193605.38,249452.05])|[49.400225119840684,0.5997748801593231]|[0.9880045023968136,0.01199549760318646] |0.0       |\n",
      "+-----+-------------------------------------+---------------------------------------+-----------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_rf.show(truncate = False, n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Perceptron (NNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo de predição\n",
    "start_time =  time.time()\n",
    "layers = [7, 5, 5, 2]\n",
    "trainer = MultilayerPerceptronClassifier(featuresCol='features', labelCol='label',\\\n",
    "          maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "model_nnp = trainer.fit(train)\n",
    "time_nnp_train = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução do modelo de predição na base de teste\n",
    "start_time =  time.time()\n",
    "result_nnp = model_nnp.transform(test)\n",
    "time_nnp_pred = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da acurácia do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='accuracy')\n",
    "accuracy_nnp = evaluator.evaluate(result_nnp) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo do recall do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedRecall')\n",
    "recall_nnp = evaluator.evaluate(result_nnp) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da precisão do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedPrecision')\n",
    "precision_nnp = evaluator.evaluate(result_nnp) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da F1 score do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='f1')\n",
    "f1_nnp = evaluator.evaluate(result_nnp) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1902  538]\n",
      " [  47 2380]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusão\n",
    "y_true = result_nnp.select(\"label\").toPandas()\n",
    "y_pred = result_nnp.select(\"prediction\").toPandas()\n",
    "mc_nnp = confusion_matrix(y_true, y_pred)\n",
    "tn_nnp, fp_nnp, fn_nnp, tp_nnp = confusion_matrix(y_true, y_pred).ravel()\n",
    "print(mc_nnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados do modelo Neural Network Perceptron:\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|acurácia|recall|precisão|f1 score|falso positivo|falso negativo|tempo treinamento|tempo predição|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|   87.98| 87.98|    89.6|   87.86|           538|            47|            18.01|          0.07|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibição dos resultados\n",
    "evaluator_nnp = spark.createDataFrame(\n",
    "    [(round(accuracy_nnp,2), round(recall_nnp,2), round(precision_nnp,2), round(f1_nnp,2),\\\n",
    "      int(fp_nnp), int(fn_nnp),\\\n",
    "      round(time_nnp_train,2), round(time_nnp_pred,2))],\\\n",
    "    ['acurácia','recall','precisão','f1 score',\\\n",
    "     'falso positivo', 'falso negativo',\\\n",
    "     'tempo treinamento','tempo predição'])\n",
    "print(\"Resultados do modelo Neural Network Perceptron:\")\n",
    "evaluator_nnp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------+-----------------------------------------+---------------------------------------+----------+\n",
      "|label|features                             |rawPrediction                            |probability                            |prediction|\n",
      "+-----+-------------------------------------+-----------------------------------------+---------------------------------------+----------+\n",
      "|0.0  |(7,[0,1,4],[1.0,10782.94,100585.0])  |[1.133290816479007,-0.016314562083979967]|[0.759438830350663,0.24056116964933716]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[1.133290816479007,-0.016314562083979967]|[0.759438830350663,0.24056116964933716]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[1.133290816479007,-0.016314562083979967]|[0.759438830350663,0.24056116964933716]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,34629.16,38735.74])  |[0.920516837987315,0.17737734588834053]  |[0.6776819948854382,0.3223180051145617]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,193605.38,249452.05])|[1.133290816479007,-0.016314562083979967]|[0.759438830350663,0.24056116964933716]|0.0       |\n",
      "+-----+-------------------------------------+-----------------------------------------+---------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_nnp.show(truncate = False, n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo de predição\n",
    "start_time =  time.time()\n",
    "trainer = NaiveBayes(smoothing=1.0, modelType='multinomial')\n",
    "model_nb = trainer.fit(train)\n",
    "time_nb_train = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução do modelo de predição na base de teste\n",
    "start_time =  time.time()\n",
    "result_nb = model_nb.transform(test)\n",
    "time_nb_pred = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da acurácia do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='accuracy')\n",
    "accuracy_nb = evaluator.evaluate(result_nb) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo do recall do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedRecall')\n",
    "recall_nb = evaluator.evaluate(result_nb) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da precisão do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedPrecision')\n",
    "precision_nb = evaluator.evaluate(result_nb) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da F1 score do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='f1')\n",
    "f1_nb = evaluator.evaluate(result_nb) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1549  891]\n",
      " [ 301 2126]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusão\n",
    "y_true = result_nb.select(\"label\").toPandas()\n",
    "y_pred = result_nb.select(\"prediction\").toPandas()\n",
    "mc_nb = confusion_matrix(y_true, y_pred)\n",
    "tn_nb, fp_nb, fn_nb, tp_nb = confusion_matrix(y_true, y_pred).ravel()\n",
    "print(mc_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados do modelo Naive Bayes:\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|acurácia|recall|precisão|f1 score|falso positivo|falso negativo|tempo treinamento|tempo predição|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|   75.51| 75.51|   77.12|   75.15|           891|           301|             6.51|          0.06|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibição dos resultados\n",
    "evaluator_nb = spark.createDataFrame(\n",
    "    [(round(accuracy_nb,2), round(recall_nb,2), round(precision_nb,2), round(f1_nb,2),\\\n",
    "      int(fp_nb), int(fn_nb),\\\n",
    "      round(time_nb_train,2), round(time_nb_pred,2))],\\\n",
    "    ['acurácia','recall','precisão','f1 score',\\\n",
    "     'falso positivo', 'falso negativo',\\\n",
    "     'tempo treinamento','tempo predição'])\n",
    "print(\"Resultados do modelo Naive Bayes:\")\n",
    "evaluator_nb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------+-----------------------------------------+-----------+----------+\n",
      "|label|features                             |rawPrediction                            |probability|prediction|\n",
      "+-----+-------------------------------------+-----------------------------------------+-----------+----------+\n",
      "|0.0  |(7,[0,1,4],[1.0,10782.94,100585.0])  |[-185597.63318901055,-241851.82351438346]|[1.0,0.0]  |0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[-551910.7905068266,-809608.9740410324]  |[1.0,0.0]  |0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[-551910.7905068266,-809608.9740410324]  |[1.0,0.0]  |0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,34629.16,38735.74])  |[-184955.59537742924,-131224.79568210608]|[0.0,1.0]  |1.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,193605.38,249452.05])|[-1081538.196092862,-808275.1143704863]  |[0.0,1.0]  |1.0       |\n",
      "+-----+-------------------------------------+-----------------------------------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_nb.show(truncate = False, n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo de predição\n",
    "start_time =  time.time()\n",
    "trainer = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "model_lr = trainer.fit(train)\n",
    "time_lr_train = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução do modelo de predição na base de teste\n",
    "start_time =  time.time()\n",
    "result_lr = model_lr.transform(test)\n",
    "time_lr_pred = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da acurácia do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='accuracy')\n",
    "accuracy_lr = evaluator.evaluate(result_lr) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo do recall do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedRecall')\n",
    "recall_lr = evaluator.evaluate(result_lr) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da precisão do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedPrecision')\n",
    "precision_lr = evaluator.evaluate(result_lr) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da F1 score do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='f1')\n",
    "f1_lr = evaluator.evaluate(result_lr) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2438    2]\n",
      " [  64 2363]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusão\n",
    "y_true = result_lr.select(\"label\").toPandas()\n",
    "y_pred = result_lr.select(\"prediction\").toPandas()\n",
    "mc_lr = confusion_matrix(y_true, y_pred)\n",
    "tn_lr, fp_lr, fn_lr, tp_lr = confusion_matrix(y_true, y_pred).ravel()\n",
    "print(mc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados do modelo Logistic Regression:\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|acurácia|recall|precisão|f1 score|falso positivo|falso negativo|tempo treinamento|tempo predição|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|   98.64| 98.64|   98.68|   98.64|             2|            64|              9.1|          0.03|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibição dos resultados\n",
    "evaluator_lr = spark.createDataFrame(\n",
    "    [(round(accuracy_lr,2), round(recall_lr,2), round(precision_lr,2), round(f1_lr,2),\\\n",
    "      int(fp_lr), int(fn_lr),\\\n",
    "      round(time_lr_train,2), round(time_lr_pred,2))],\\\n",
    "    ['acurácia','recall','precisão','f1 score',\\\n",
    "     'falso positivo', 'falso negativo',\\\n",
    "     'tempo treinamento','tempo predição'])\n",
    "print(\"Resultados do modelo Logistic Regression:\")\n",
    "evaluator_lr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "|label|features                             |rawPrediction                           |probability                             |prediction|\n",
      "+-----+-------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "|0.0  |(7,[0,1,4],[1.0,10782.94,100585.0])  |[1.5862996712454818,-1.5862996712454818]|[0.8300948556474514,0.16990514435254858]|0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[1.4886690792839434,-1.4886690792839434]|[0.815878424625442,0.18412157537455792] |0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[1.4886690792839434,-1.4886690792839434]|[0.815878424625442,0.18412157537455792] |0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,34629.16,38735.74])  |[1.5487225374262987,-1.5487225374262987]|[0.8247291499651642,0.1752708500348357] |0.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,193605.38,249452.05])|[1.0644079542114124,-1.0644079542114124]|[0.7435320095447154,0.25646799045528457]|0.0       |\n",
      "+-----+-------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_lr.show(truncate = False, n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suport Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo de predição\n",
    "start_time =  time.time()\n",
    "trainer = LinearSVC(featuresCol='features', labelCol='label',\\\n",
    "                    maxIter=100, regParam=0.1)\n",
    "model_svm = trainer.fit(train)\n",
    "time_svm_train = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução do modelo de predição na base de teste\n",
    "start_time =  time.time()\n",
    "result_svm = model_svm.transform(test)\n",
    "time_svm_pred = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da acurácia do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='accuracy')\n",
    "accuracy_svm = evaluator.evaluate(result_svm) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo do recall do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedRecall')\n",
    "recall_svm = evaluator.evaluate(result_svm) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da precisão do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='weightedPrecision')\n",
    "precision_svm = evaluator.evaluate(result_svm) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da F1 score do modelo de predição\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\\\n",
    "            metricName='f1')\n",
    "f1_svm = evaluator.evaluate(result_svm) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2211  229]\n",
      " [ 119 2308]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusão\n",
    "y_true = result_svm.select(\"label\").toPandas()\n",
    "y_pred = result_svm.select(\"prediction\").toPandas()\n",
    "mc_svm = confusion_matrix(y_true, y_pred)\n",
    "tn_svm, fp_svm, fn_svm, tp_svm = confusion_matrix(y_true, y_pred).ravel()\n",
    "print(mc_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados do modelo Suport Vector Machines:\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|acurácia|recall|precisão|f1 score|falso positivo|falso negativo|tempo treinamento|tempo predição|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "|   92.85| 92.85|   92.94|   92.85|           229|           119|           729.52|          0.08|\n",
      "+--------+------+--------+--------+--------------+--------------+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibição dos resultados\n",
    "evaluator_svm = spark.createDataFrame(\n",
    "    [(round(accuracy_svm,2), round(recall_svm,2), round(precision_svm,2), round(f1_svm,2),\\\n",
    "      int(fp_svm), int(fn_svm),\\\n",
    "      round(time_svm_train,2), round(time_svm_pred,2))],\\\n",
    "    ['acurácia','recall','precisão','f1 score',\\\n",
    "     'falso positivo', 'falso negativo',\\\n",
    "     'tempo treinamento','tempo predição'])\n",
    "print(\"Resultados do modelo Suport Vector Machines:\")\n",
    "evaluator_svm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------+------------------------------------------+----------+\n",
      "|label|features                             |rawPrediction                             |prediction|\n",
      "+-----+-------------------------------------+------------------------------------------+----------+\n",
      "|0.0  |(7,[0,1,4],[1.0,10782.94,100585.0])  |[-0.20519130192207402,0.20519130192207402]|1.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[-0.1943811660229432,0.1943811660229432]  |1.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,12401.9,349763.0])   |[-0.1943811660229432,0.1943811660229432]  |1.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,34629.16,38735.74])  |[-0.21240636640930594,0.21240636640930594]|1.0       |\n",
      "|0.0  |(7,[0,1,4],[1.0,193605.38,249452.05])|[-0.2327208356740759,0.2327208356740759]  |1.0       |\n",
      "+-----+-------------------------------------+------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_svm.show(truncate = False, n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Decision Tree','Random Forest','Neural Network Perceptron','Naive Bayes','Logistic Regression','Suport Vector Machines']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking Accuracy %\n",
      "+-------------------------+-----------------+\n",
      "|Modelo                   |Acuracia         |\n",
      "+-------------------------+-----------------+\n",
      "|Random Forest            |99.71234846928293|\n",
      "|Decision Tree            |99.69180193137457|\n",
      "|Logistic Regression      |98.64392849804808|\n",
      "|Neural Network Perceptron|87.98027532360797|\n",
      "|Naive Bayes              |75.50852681323197|\n",
      "|Suport Vector Machines   |75.50852681323197|\n",
      "+-------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Ranking Accuracy %')\n",
    "\n",
    "list = ((models[0],accuracy_dt),\\\n",
    "        (models[1],accuracy_rf),\\\n",
    "        (models[2],accuracy_nnp),\\\n",
    "        (models[3],accuracy_nb),\\\n",
    "        (models[4],accuracy_lr),\\\n",
    "        (models[5],accuracy_nb))\n",
    "df_acuracia = spark.createDataFrame(list, ['Modelo', 'Acuracia'])\n",
    "df_acuracia.sort(df_acuracia.Acuracia.desc()).show(truncate = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking\n",
      "+-------------------------+-----------------+\n",
      "|Modelo                   |Recall           |\n",
      "+-------------------------+-----------------+\n",
      "|Random Forest            |99.71234846928292|\n",
      "|Decision Tree            |99.69180193137457|\n",
      "|Logistic Regression      |98.64392849804808|\n",
      "|Suport Vector Machines   |92.84980480788987|\n",
      "|Neural Network Perceptron|87.98027532360797|\n",
      "|Naive Bayes              |75.50852681323197|\n",
      "+-------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Ranking')\n",
    "\n",
    "list = ((models[0],recall_dt),\\\n",
    "        (models[1],recall_rf),\\\n",
    "        (models[2],recall_nnp),\\\n",
    "        (models[3],recall_nb),\\\n",
    "        (models[4],recall_lr),\\\n",
    "        (models[5],recall_svm))\n",
    "df_recall = spark.createDataFrame(list, ['Modelo', 'Recall'])\n",
    "df_recall.sort(df_recall.Recall.desc()).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking Precision %\n",
      "+-------------------------+-----------------+\n",
      "|Modelo                   |Precisao         |\n",
      "+-------------------------+-----------------+\n",
      "|Random Forest            |99.71398951306045|\n",
      "|Decision Tree            |99.69368501529692|\n",
      "|Logistic Regression      |98.67543661321872|\n",
      "|Suport Vector Machines   |92.93838143225915|\n",
      "|Neural Network Perceptron|89.59701340348573|\n",
      "|Naive Bayes              |77.11625293876516|\n",
      "+-------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Ranking Precision %')\n",
    "\n",
    "list = ((models[0],precision_dt),\\\n",
    "        (models[1],precision_rf),\\\n",
    "        (models[2],precision_nnp),\\\n",
    "        (models[3],precision_nb),\\\n",
    "        (models[4],precision_lr),\\\n",
    "        (models[5],precision_svm))\n",
    "df_precision = spark.createDataFrame(list, ['Modelo', 'Precisao'])\n",
    "df_precision.sort(df_precision.Precisao.desc()).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----------------+\n",
      "|Modelo                   |F1               |\n",
      "+-------------------------+-----------------+\n",
      "|Random Forest            |99.71234387889739|\n",
      "|Decision Tree            |99.69179646661719|\n",
      "|Logistic Regression      |98.64366223187787|\n",
      "|Suport Vector Machines   |92.8465827587081 |\n",
      "|Neural Network Perceptron|87.86002379155052|\n",
      "|Naive Bayes              |75.15152754554644|\n",
      "+-------------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list = ((models[0],f1_dt),\\\n",
    "        (models[1],f1_rf),\\\n",
    "        (models[2],f1_nnp),\\\n",
    "        (models[3],f1_nb),\\\n",
    "        (models[4],f1_lr),\\\n",
    "        (models[5],f1_svm))\n",
    "df_f1 = spark.createDataFrame(list, ['Modelo', 'F1'])\n",
    "df_f1.sort(df_f1.F1.desc()).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempo de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------------+\n",
      "|Modelo                   |Tempo_Treinamento |\n",
      "+-------------------------+------------------+\n",
      "|Naive Bayes              |6.50537896156311  |\n",
      "|Logistic Regression      |9.096431016921997 |\n",
      "|Decision Tree            |9.177486658096313 |\n",
      "|Random Forest            |9.961931467056274 |\n",
      "|Neural Network Perceptron|18.005624532699585|\n",
      "|Suport Vector Machines   |729.5157809257507 |\n",
      "+-------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list = ((models[0],time_dt_train),\\\n",
    "        (models[1],time_rf_train),\\\n",
    "        (models[2],time_nnp_train),\\\n",
    "        (models[3],time_nb_train),\\\n",
    "        (models[4],time_lr_train),\\\n",
    "        (models[5],time_svm_train))\n",
    "df_time_train = spark.createDataFrame(list, ['Modelo', 'Tempo_Treinamento'])\n",
    "df_time_train.sort(df_time_train.Tempo_Treinamento.asc()).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempo de Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------+\n",
      "|Modelo                   |Tempo_Predicao     |\n",
      "+-------------------------+-------------------+\n",
      "|Neural Network Perceptron|0.07020425796508789|\n",
      "|Naive Bayes              |0.07020425796508789|\n",
      "|Logistic Regression      |0.07020425796508789|\n",
      "|Suport Vector Machines   |0.07020425796508789|\n",
      "|Decision Tree            |0.0850825309753418 |\n",
      "|Random Forest            |0.08755016326904297|\n",
      "+-------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list = ((models[0],time_dt_pred),\\\n",
    "        (models[1],time_rf_pred),\\\n",
    "        (models[2],time_nnp_pred),\\\n",
    "        (models[3],time_nnp_pred),\\\n",
    "        (models[4],time_nnp_pred),\\\n",
    "        (models[5],time_nnp_pred))\n",
    "df_time_pred = spark.createDataFrame(list, ['Modelo', 'Tempo_Predicao'])\n",
    "df_time_pred.sort(df_time_pred.Tempo_Predicao.asc()).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Falso Positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------+\n",
      "|Modelo                   |Falso_Positivo|\n",
      "+-------------------------+--------------+\n",
      "|Random Forest            |0             |\n",
      "|Decision Tree            |0             |\n",
      "|Logistic Regression      |2             |\n",
      "|Suport Vector Machines   |229           |\n",
      "|Neural Network Perceptron|538           |\n",
      "|Naive Bayes              |891           |\n",
      "+-------------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list = ((models[0],int(fp_dt)),\\\n",
    "        (models[1],int(fp_rf)),\\\n",
    "        (models[2],int(fp_nnp)),\\\n",
    "        (models[3],int(fp_nb)),\\\n",
    "        (models[4],int(fp_lr)),\\\n",
    "        (models[5],int(fp_svm)))\n",
    "df_fp = spark.createDataFrame(list, ['Modelo', 'Falso_Positivo'])\n",
    "df_fp.sort(df_fp.Falso_Positivo.asc()).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Falso Negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------+\n",
      "|Modelo                   |Falso_Negativo|\n",
      "+-------------------------+--------------+\n",
      "|Random Forest            |14            |\n",
      "|Decision Tree            |15            |\n",
      "|Neural Network Perceptron|47            |\n",
      "|Logistic Regression      |64            |\n",
      "|Suport Vector Machines   |119           |\n",
      "|Naive Bayes              |301           |\n",
      "+-------------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list = ((models[0],int(fn_dt)),\\\n",
    "        (models[1],int(fn_rf)),\\\n",
    "        (models[2],int(fn_nnp)),\\\n",
    "        (models[3],int(fn_nb)),\\\n",
    "        (models[4],int(fn_lr)),\\\n",
    "        (models[5], int(fn_svm)))\n",
    "df_fn = spark.createDataFrame(list, ['Modelo', 'Falso_Negativo'])\n",
    "df_fn.sort(df_fn.Falso_Negativo.asc()).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----------------+--------------+--------------+------------------+-------------------+\n",
      "|Modelo                   |Acuracia         |Falso_Positivo|Falso_Negativo|Tempo_Treinamento |Tempo_Predicao     |\n",
      "+-------------------------+-----------------+--------------+--------------+------------------+-------------------+\n",
      "|Random Forest            |99.71234846928293|0             |14            |9.961931467056274 |0.08755016326904297|\n",
      "|Decision Tree            |99.69180193137457|0             |15            |9.177486658096313 |0.0850825309753418 |\n",
      "|Logistic Regression      |98.64392849804808|2             |64            |9.096431016921997 |0.07020425796508789|\n",
      "|Neural Network Perceptron|87.98027532360797|538           |47            |18.005624532699585|0.07020425796508789|\n",
      "|Naive Bayes              |75.50852681323197|891           |301           |6.50537896156311  |0.07020425796508789|\n",
      "|Suport Vector Machines   |75.50852681323197|229           |119           |729.5157809257507 |0.07020425796508789|\n",
      "+-------------------------+-----------------+--------------+--------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_acuracia.join(df_fp, \"Modelo\")\n",
    "df = df.join(df_fn, \"Modelo\")\n",
    "df = df.join(df_time_train, \"Modelo\")\n",
    "df = df.join(df_time_pred, \"Modelo\")\n",
    "df.sort(df.Acuracia.desc()).show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de classificação do melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------------+--------------+--------------+--------------+---------+-----+\n",
      "|step| amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|indexType|label|\n",
      "+----+-------+-------------+--------------+--------------+--------------+---------+-----+\n",
      "|   1|9839.64|     170136.0|     160296.36|           0.0|           0.0|      2.0|  0.0|\n",
      "+----+-------+-------------+--------------+--------------+--------------+---------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_selecionado.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valores para teste\n",
    "entradas = [1.0, 9839.64,170136.0, 160296.36,0.0,0.0,2.0]\n",
    "resultado = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando o dataframe Spark para execução do modelo\n",
    "df_teste = spark.createDataFrame(\n",
    "    [(resultado,\\\n",
    "      Vectors.dense([entradas[0],entradas[1],entradas[2],entradas[3],entradas[4],entradas[5],entradas[6]]))],\n",
    "    ['label', 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#resultado da predição utilizando o modelo DT\n",
    "resultado = model_dt.transform(df_teste)\n",
    "resultado.select('label','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
